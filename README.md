I was curious about how the gradient descent algorithm in linear regression minimizes the cost function to find the best-fitting line for a dataset. 
To explore this, I analyzed the intuition behind the process using both a manual approach and Python programming. I was amazed by how the model performs these calculations!
I created a problem using a dataset with two features and evaluated it using the mean squared error (MSE) as the cost function. 
For the manual calculations, I performed two iterations, which, although time-consuming, produced the same results as the Python implementation.
